---
title: "Variation in distance between consecutive animal locations"
abstract: |
  This should be the abstract
output:
  word_document:
    reference_docx: docx_ref.docx
  html_document:
    df_print: paged
bibliography: aracari_refs.bib
csl: ecology-letters.csl
---

# Introduction

Movement is a fundamental ecological process, critical to an animal's biology and it's interactions with the environment. The study of animal movement tends to focus on four basic mechanistic questions: the why, when, where, and how an animal moves, and these questions can be answered at the scale of individuals or populations. A general framework for movement ecology is needed to link movement patterns and processes. Such a framework would start with a focus on movement itself and the individual's internal state, navigation capacity, motion capacity, and responses to external factors [@nathan2008movement]. The overall goal of studying movement is to find the linkages between the causes and mechanisms of animal movement, that explain spatiotemporal patterns that then feed back into various ecological and evolutionary processes. However, we can also focus on the effects and consequences that different movement patterns can have over species interactions and other ecological processes.

Random walks have been used broadly in biology to model movement of animals and microorganisms, starting with the simplest models of movement using uncorrelated and unbiased random walks [@codling2008random]. These movement models show no preference in direction and movement at each step is completely independent of the direction taken in previous movements. Extensions of simple random walk processes are regularly used to accommodate for more complex behaviors or to include drift. Some of these extensions involve the use of correlated random walks, which incorporate a correlation between directions in successive movements, biased random walks, which incorporate a directional bias, or even building movement models as mixtures of random walks to account for more complex behaviors [@morales2004extracting]. Modeling approaches using random walks generally assume a homogeneous environment and behaviors that don't drastically change the movement pattern [@kareiva1983analyzing]. A simple random walk approximates displacements by connecting a series of straight lines, and can summarize animal movement based on parameters for movement length and turning angle, or the use of net squared displacement. Connecting theoretical movement models based on correlated random walks to data had often relied on the use of these parameters or displacement measures [@turchin1998quantitative], but more current and efficient approaches have used likelihood-based techniques to estimate parameters by fitting a discrete approximation of the model directly to the location data [@jonsen2003meta].

   In the context of species interactions and the consequences of animal movement to dispersal, the general focus has been on understanding how the typical movement patterns, built around average measures at population levels, can influence plant population spread [@levey2005effects], seed dispersal [@jones2017closing, @holbrook2007using], pollen dispersal [@garcia2007contemporary], and even pathogens [@shaw2017vector]. Animal movement can be modeled with a simple diffusion process or a random walk [@jones2017closing; @levey2005effects], with the simplest approach assuming model parameters are the same across individuals, something known as 'complete pooling' [@langrock2012flexible]. This focus on generality has driven to a lack of frameworks for understanding how variation in animal movement is maintained, and the consequences of this variation across populations and communities. From the animal movement perspective, some alternatives have been considered to incorporate individual variation with 'no pooling' or 'partial pooling' approaches, where each or some individuals have their own set of parameters [@patterson2009classifying, @jonsen2006robust], however a high number of parameters quickly limits applications to high levels of individual variation. The decision to pool data or not may also come from the modeling framework chosen, as frameworks that allow for random effects may have a better structure to incorporate this variation than simpler frameworks. Recent calls for incorporating individual variation in movement and their consequences to seed dispersal or even pathogen spread [@snell2019consequences, @shaw2020causes] have pushed for the need to develop theory that explores different types of variation in movement patterns to understand its consequences across ecological organizational levels. In particular, when considering species interactions, incorporating individual variation becomes essential to understand how positive or negative feedback loops play into the maintenance of variation in movement as individuals respond to external factors in their environment.
  
  We focus here on developing a process to analyze animal movement sequences based on movement lengths, or step lengths, and turning angle probability distributions. We assume the movement is a correlated random walk and derive expected square displacements associated to a number of consecutive moves under various probability distribution models. Unlike other studies which focus on deciphering the underlying behaviors from animal movement data, our focus was to uncover potential differences between individuals and how these differences can be obscured when modeling population-level animal movement. We know these simple correlated random walks, or simple movement models might not be enough to describe net displacements under more complex processes, for which developments in higher order markov processes show to be promising. However, our goal in this study was to use a simpler model and focus on potential differences that arise when comparing data from multiple individuals under frameworks that completely pool data in contrast to those that don't.
  
# Methods

## Animal movement model

As in other papers. Note that we adopt the convention of using upper case letters for random variables and lower case letters for possible numerical values of these random variables. 

## Description of the models considered

## Specific case with telemetry data  

We focused our study of individual variation on the many-banded araçari (*Pterglossus pluricinctus*), a small toucan in Yasuní National Park, Ecuador. We used previously collected data from studies using radiotelemetry to estimate home ranges and evaluate the potential seed dispersal distances for the *Virola flexuosa* tree [@holbrook2011home, holbrook2007usin]. Over a period of four years, from 2001 to 2005, *P. pluricinctus* individuals were captured and radio-transmitters were attached at the base of the central tail feathers [@holbrook2011home]. Toucan locations were estimated by triangulation using receivers and hand-held antennas, with tracking periods lasting between 4-5 hours per day, locating individual birds every 15 minutes. Further details on field methods can be found in Holbrook [-@holbrook2011home]. It is important to note that these methods did not track all birds simultaneously, and that although individual toucan locations were attempted every 15 minutes, this was not always possible, thus some successive locations have time categories associated to multiples of 15. Due to the nature of the data, and the irregular time lags between two consecutive locations, previous work calculated movement rate for each individual in order to take advantage of all the data despite variable time intervals [see Table 1 in @holbrook2011home]. Movement rates were calculated as the displacement in meters over the total length of the tracking period in minutes, where the tracking period was defined as the total active tracking time for a bird over the season when the data was collected. In other words, the movement rate could be defined as the average velocity of the animal over the entire tracking period, and thus there is one movement rate value associated to each individual bird. 
In our case, we wanted to extend the use of the telemetry data and use all locations in a modeling framework. From the relocation data, we calculated animal trajectories by considering discrete steps between successive relocations of each animal [@turchin1998quantitative], quantifying their turning angle after each movement, estimating the Euclidean distance between successive relocations, and estimating the velocity for each segment as the displacement distance divided by the length of the time interval. We used the package 'adehabitatLT'[@adehabitatLT] in R [@Rlang] to calculate other descriptive parameters for each trajectory, such as turning angles and net squared displacement.



# Results  
The majority of trajectories obtained were regular, with 15 minute time lags between successive relocations, however, some relocations were gathered at different time intervals, making them irregular. To analyze all trajectories and compare their descriptive parameters, we decided to work under a velocity-based framework.

<span style="color:red">For our analyses, we focused on toucans with a minimum of **20?** recorded locations, and we calculated turning angles (in radians), and the associated Euclidean step lengths in meters for each successive set of locations and turning directions. We worked under a velocity-based framework, and thus divided step lengths by the time interval during which they were recorded. This gave us a total of **600ish?** data points for turning angles and velocities.red</span>

What do we consider a trajectory? The path followed by consecutive relocations during a tracking session. The tracking session for this data is the 4-5 hour period each day that they follow the bird. Then, the number of relocations for each trajectory varies from one to 26, with a mean of 4 relocations. This is a limitation of the data, since it's not easy to characterize a full trajectory of movement with such a small number of relocations in a trajectory. 

Dealing with the issue of autocorrelation in this case: what does that mean? Or we just assume each step is independent from the others. Think I saw this in the Kareiva Shigesada paper. 
```{r eval=FALSE}
# For this to run I need to move the load of data and such higher up
aracari_df %>%
  group_by(id, burst) %>% 
  tally() -> relocs 

# Having a minimum number of relocations for "time series analysis" or something, fitting.
relocs %>% 
  filter(n >= 5) %>% 
  distinct(id)


relocs %>% 
  ggplot(., aes(x = n, fill = id)) +
  geom_histogram()
summary(relocs$n)
```


```{r eval=FALSE}
aracari_df %>% 
  filter(R2n >0) %>% 
  ggplot(., aes(x = R2n)) +
  geom_histogram() +
  facet_wrap(~id)
```


**Could I find anything pre HMMs of SSMs? Wondering what people could do before? And wondering this because we have broken up tracking periods, not continuous ones**  
Seems like I need to focus more on random walks
  
Assume weibull distributions for step length and wrapped cauchy distributions for the turning angles [@langrock2012flexible], but they tried Gamma and von Mises, respectively, but got outperformed by AIC. Used negative binomial for the state dwell times. 
  
Random walks used broadly in biology to characterize animal and cell movement. Describes que commonly used distributions for angles: von Mises, wrapped normal and wrapped Cauchy distributions. [@codling2008random]
- IDEA: so maybe use these distributions for the angles. We might see that there is not much difference in angle movement across individuals? They all tend to move forward perhaps, or something like that, and where the real differences are is in the distances. 
- Also might be intriguing to incorporate the time as a set of multiple random walks? or repeats the velocity value for that number of minutes. Maybe just using a correlated random walk, which takes into account short-term correlations in the direction of movement?
  - Codling describes this as a velocity jump process, since the markov process is the walker's velocity rather than the location. Details at the end of page 7. 
  - We consider the individuals moving in space at a constant speed $\nu$, and at each time step $\tau$ each individual changes direction and moves a distance $\delta$ in a new direction (with probability $r=\lambda\tau$), or moves a distance $\delta$ in the previous direction (with probability $q=1-\lambda\tau$). Hence, turning events occur as a Poisson process with rate $\lambda$. **This is textual from paper, so modify** Their focus is also on multiple individuals at the same time, and the density of individuals at a given time and location.
    - In my case, the distance $\delta$ would also be randomly sampled, or this are the velocities I suppose. So, perhaps it is constant speed, and the distance is actually times to account for 15, 30, etc minutes based on the data. 
    - Remember too that this velocity $\nu$ is actually the distance over time $\delta/\tau$
  - Pg11. A correlated random walk, CRW, consisting of a series of independet draws from a step length PDF and a turning angle PDF for each step, a first order markov process.
    - using mean square displacement. The effect of step length variability on MSD can be quite significant.
    - MSD being of interest to ecologists due to its relation with the diffusion coefficient D. equations 2.13 and 2.14
** Should write a conclusion about this paper**
  



[@kareiva1983analyzing] - approximating displacements by connecting a series of straight lines, and thus summarize animal movement based on parameters for movement length and turning angle. Using square displacement instead of linear displacement, because it's expectation can be calculated from turning angles and step lengths. Assume that the length of each move and the turning angle are independent random variables, each with its own probability density. Assume that a series of moves can be represented by random draws from these probability densities, and since each random draw is independent from the preceding ones, the random draw process is a first order markov chain. The result is a correlated random walk, and the distribution g(theta) gives a measure of the degree to which the angles of movement are correlated.
*Would be interesting to add a figure with what I am actually analyzing. So, visually show how the gps locations get turned into straight lines, and angles, with an associated time interval. Or we could just multiply everything? So have it all for 15 minute intervals, and then repeat the ones that went on longer, perhaps set a limit for 60 minutes?*


probabilistic rules of movement. 




  





"Location accuracy using radio telemetry may be reduced in tropical forests... conservative distance categories of 100-m increments to better represent precision. Time categories: 15, 30, 60, 90 minutes. Then calculated probability of movements made within each distance category within each time category, summed across each time category to give a final probability for each distance category."

"Distances travelled per movement bout ranged from 0 to >2000m. Strong leptokurtic distributions of movements with most being <300m. Longest recorded movement for Pluricinctus is 3665m (recorded in 30 minutes)" *this is a corresponding velocity of `r 3665/30` meters per minute.


Evaluating models with their individual-specific counterparts, using AIC or BIC. In individual-specific models the AIC results from the joint likelihood of the individual-specific models.     

Consider incorporating NAs for missed observations so we keep the regular 15 minute time interval.


$$AIC{_{indlevel}} = 2 \cdot \sum \left ( number parameters \right ) + 2 \cdot \sum \left ( negative log likelihood \right )$$

$$ AICc{_{indlevel}} =  AIC{_{indlevel}} + (2 \cdot \sum{nparams}  \cdot \left(\sum{nparams}+1\right)/\left(\sum{observations} - \left(\sum{nparams} - 1\right)\right)$$


$$BIC_{indlevel} = \ln{\sum observations} \cdot \sum{number parameters} + 2\cdot \sum {negative log likelihood}$$

```{r setup, include=FALSE}
# knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
knitr::opts_chunk$set(message = FALSE, warning = FALSE, 
                      eval=FALSE,
                      echo = FALSE)

```

```{r}
library(tidyverse)
library(aracari)
library(stringr)
library(fitdistrplus)
library(cowplot)
library(RColorBrewer)
library(gt)

theme_set(theme_bw())
```

```{r}
aracari_df <- readRDS("aracari_df.RDS")
```

```{r eval=FALSE}
# Which individuals will we conside? Need at least a certain number of data points to fit distributions
# Don't remove any yet, just make sure you make it clear how many data points you have for each

aracari_df %>% 
  dplyr::filter(dist != 0) %>% 
  group_by(id) %>% 
  tally()

aracari_df %>% 
  mutate(tmin = dt/60,
         mpm = dist/tmin) %>% 
  drop_na(tmin) %>% 
  filter(tmin == 60) %>% 
  group_by(id) %>% 
  tally() %>% 
  filter(n >=20)

```


```{r eval=FALSE}
# Table replicating results from Holbrook 2011, movement rates
# The values are close, but not the same, so I don't know how Kimberly estimated her movement rates

aracari_df %>%
  drop_na(dist) %>% 
  mutate(mpm = dist/(dt/60)) %>% 
  group_by(id) %>% 
  summarise(movrate = mean(mpm)) %>% 
  ungroup() %>% 
  summarise(mean = mean(movrate),
            sd = sd(movrate),
            median = median(movrate),
            range = range(movrate))

aracari_df %>%
  drop_na(dist) %>% 
  group_by(id) %>% 
  summarise(movrate = sum(dist)/sum(dt/60)) %>% 
  ungroup() %>% 
  summarise(mean = mean(movrate),
            sd = sd(movrate),
            median = median(movrate),
            range = range(movrate))

```


```{r eval=FALSE}
focus <- "dist15"

df <- aracari_df %>%
  mutate(tmin = dt/60,
         mpm = dist/tmin,
         Bird_ID = paste0("B", id),
         focus = mpm) %>% 
  drop_na(tmin) %>% 
  filter(tmin == 15) %>% 
  dplyr::filter(dist != 0) %>% 
  group_by(id) %>%
  filter(., n() >= 20) %>%
  ungroup()
  
  dist.used <- c( "exp", "gamma", "weibull", "lnorm")
  param <- c("rate", "shape", "rate", "shape", "scale", "meanlog", "sdlog")
  dist <- c("exp", "gamma", "gamma", "weibull", "weibull", "lnorm", "lnorm")
  kpars <- c(1, 2, 2, 2, 2, 2, 2)
```

```{r eval=FALSE}
df %>% 
  ggplot(., aes(x = abs.angle)) +
  geom_histogram() +
  facet_wrap(~Bird_ID)
```

```{r eval=FALSE}
df %>%
  drop_na(rel.angle) %>%
  mutate(d.angle = ifelse(rel.angle > 0, rel.angle * 180/pi,
                          rel.angle * 180/pi + 360)) %>%
  ggplot(., aes(x = d.angle)) +
  #facet_wrap(~id) +
  geom_histogram(color = "grey", fill = "grey") +
  coord_polar(theta = "x", start = -pi/2, direction = -1) +
  scale_x_continuous(breaks = seq(0, 360, 30), limits = c(0, 360)) +
  theme_minimal() +
  theme(axis.title = element_blank(),
        axis.text.y = element_blank(),
        legend.position = "none")
```

```{r}
# Create my focus variable and only for individuals with 30+ observations

# focus <- "dist"
# focus <- "R2n"
 focus <- "mpm"
# focus <- "m15"

if(focus == "dist"){
  df <- aracari_df %>%
  dplyr::filter(dist != 0) %>%
  group_by(id) %>%
  filter(., n() >= 30) %>%
  ungroup() %>%
  dplyr::filter(dist != 0) %>% 
    mutate(Bird_ID = paste0("B", id),
           focus = dist)
  
  dist.used <- c("lnorm", "weibull", "cauchy")
  param <- c("meanlog", "sdlog", "shape", "scale", "location", "scale")
  dist <- c("lnorm", "lnorm", "weibull", "weibull", "cauchy", "cauchy")
  kpars <- c(2, 2, 2, 2, 2, 2)
}

if(focus == "R2n"){
  df <- aracari_df %>%
  dplyr::filter(R2n != 0) %>%
  group_by(id) %>%
  filter(., n() >= 30) %>%
  ungroup() %>%
  dplyr::filter(R2n != 0) %>% 
    mutate(Bird_ID = paste0("B", id),
           focus = sqrt(R2n))
  
  dist.used <- c( "exp", "gamma", "weibull", "lnorm")
  param <- c("rate", "shape", "rate", "shape", "scale", "meanlog", "sdlog")
  dist <- c("exp", "gamma", "gamma", "weibull", "weibull", "lnorm", "lnorm")
  kpars <- c(1, 2, 2, 2, 2, 2, 2)
}

if(focus == "mpm"){
  df <- aracari_df %>% 
  dplyr::filter(dist != 0) %>% 
  group_by(id) %>%
  filter(., n() >= 30) %>%
  ungroup() %>%
  mutate(tmin = dt/60,
         mpm = dist/tmin,
         Bird_ID = paste0("B", id),
         focus = mpm) %>% 
  dplyr::filter(., mpm != 0)
  
  dist.used <- c( "exp", "gamma", "weibull", "lnorm")
  param <- c("rate", "shape", "rate", "shape", "scale", "meanlog", "sdlog")
  dist <- c("exp", "gamma", "gamma", "weibull", "weibull", "lnorm", "lnorm")
  kpars <- c(1, 2, 2, 2, 2, 2, 2)
}

if(focus == "m15"){
  df <- aracari_df %>% 
  dplyr::filter(dist != 0) %>% 
  group_by(id) %>%
  filter(., n() >= 30) %>%
  ungroup() %>%
  mutate(tmin = dt/60,
         mpm = dist/tmin,
         m15 = mpm*15,
         Bird_ID = paste0("B", id),
         focus = m15) %>% 
  dplyr::filter(., m15 != 0)
  
  dist.used <- c( "exp", "gamma", "weibull", "lnorm")
  param <- c("rate", "shape", "rate", "shape", "scale", "meanlog", "sdlog")
  dist <- c("exp", "gamma", "gamma", "weibull", "weibull", "lnorm", "lnorm")
  kpars <- c(1, 2, 2, 2, 2, 2, 2)
}


```

\newpage




### MPM: meters per minute
Due to the variation in time between consecutive locations, we scaled the step lengths to displacement in one minute.
**Visualize the variation and distribution of these distances between locations**  

```{r}
 df %>%
  ggplot(., aes((x = focus))) +
  geom_line(aes(x = focus, group = id), stat = "density", alpha = 0.4) +
  geom_line(stat = "density", color = "#1191d1", lwd = 1) +
  geom_vline(xintercept = 0, color = "grey") +
  geom_hline(yintercept = 0, color = "grey") +
  labs(y = "Density", x = paste(focus)) +
  theme_classic()


```

```{r}
df %>%
  ggplot(., aes(x = focus)) +
  facet_wrap(~id) +
  geom_line(stat = "density") +
  geom_vline(xintercept = 0, color = "grey") +
  geom_hline(yintercept = 0, color = "grey") +
  labs(y = "Density", x = paste(focus)) +
  theme_classic()
```


# Fit distribution  


```{r}

# Fit the four models for the population level data
  
pop <- lapply(dist.used, function(x){fitdist(df$focus, distr = x)})

# Get data for qqplot at population level
qqpop <- qqcomp(pop, plotstyle = "ggplot")$data
names(qqpop) <- c("theoretical", "fdist", "empirical")

# Save the population level parameters

build_fits_df <- function(x){

  nm <- deparse(substitute(x))

  x %>%
    map(., `[`, c("estimate", "sd", "loglik", "n")) %>%
    map(as_tibble) %>%
    bind_rows()
}

prms.df <- build_fits_df(pop) %>% 
  mutate(param = param,
         dist = dist,
         kpars = kpars,
         data = "pop")

# Repeating the process for data at the individual level
inds <- unique(as.character(df$Bird_ID))

# Fitting the four distributions for each individual and saving the parameters in a dataframe
ind.models <- NULL
for(i in 1:length(inds)){
  fit.df <- df %>% 
    dplyr::filter(., Bird_ID == inds[i])
  
  fit <- lapply(dist.used, function(x){fitdist(fit.df$focus, distr = x)})
  
  ind.models[[i]] <- fit
  
  assign(paste(inds[i]), fit)
  
  fit.prms <- build_fits_df(fit) %>% 
  mutate(param = param,
         dist = dist,
         kpars = kpars,
         data = inds[i])
  
  prms.df <- bind_rows(prms.df, fit.prms)
}


# Getting qqplot data for each individual
inds.models.data <- NULL
for(i in 1:length(inds)){
  x <- ind.models[[i]]
  
  qqdata <- qqcomp(x, plotstyle = "ggplot")$data %>% 
    mutate(data = inds[i])
  names(qqdata) <- c("theoretical", "fdist", "empirical", "individual")
  inds.models.data <- bind_rows(inds.models.data, qqdata)
}
```


```{r ind_QQplots, fig.width=12, fig.height=5}

qqpop %>% 
  mutate(individual = "POPULATION") %>% 
  ggplot(., aes(x = theoretical, y = empirical, color = fdist)) +
  facet_wrap(~individual) +
  #coord_equal() +
  geom_point(shape = 16, alpha = 0.8, size = 4) +
  geom_abline(intercept = 0, slope = 1) +
  labs(x = "Model Quantiles",
         y = "Empirical Quantiles") +
  #scale_color_viridis_d() +
  scale_color_brewer(palette = "Spectral", name = "Distribution") +
  theme(legend.position = c(0.8, 0.2)) +
  NULL -> a

inds.models.data%>% 
  ggplot(., aes(x = theoretical, y = empirical, color = fdist)) +
  #facet_grid(individual~fdist) +
  facet_wrap(~individual)+
    geom_point(shape = 16, alpha = 0.8, size = 3) +
    geom_abline(intercept = 0, slope = 1) +
    labs(x = "Model Quantiles",
         y = "Empirical Quantiles") +
  #scale_color_viridis_d() +
  scale_color_brewer(palette = "Spectral") +
  theme(legend.position = "none") +
  guides(color = guide_legend(title = "Distribution")) +
  #coord_equal() +
  NULL -> b

plot_grid(a,b, rel_widths = c(1,2), labels = "AUTO")

```

## Information criteria

```{r}

ic_calc <- function(n, kpars, loglik){
  
  BIC <- log(n)*kpars - 2*loglik
  AIC <- 2*kpars - 2*loglik
  AICc <- AIC + (2* kpars * (kpars+1)/(n-kpars-1))
}


prms.df %>% 
  mutate(param = str_to_upper(param), 
         dist = str_replace(dist, "exp", "Exponential"),
         dist = str_replace(dist, "gamma", "Gamma"),
         dist = str_replace(dist, "weibull", "Weibull"),
         dist = str_replace(dist, "lnorm", "Lognormal"),
         data = str_replace(data, "pop", "POP")) %>% 
  mutate(BIC = log(n)*kpars - 2*loglik,
         AIC = 2*kpars - 2*loglik,
         AICc = AIC + (2* kpars * (kpars+1)/(n-kpars-1))) %>% 
  group_by(data) %>% 
  mutate(deltaBIC = signif(BIC - min(BIC), 3),
         deltaAIC = signif(AIC - min(AIC), 3),
         deltaAICc = signif(AICc - min(AICc), 3)) %>% 
  mutate(best_bic = ifelse(deltaBIC == 0, "#ffaa00", "black"),
         best_aic = ifelse(deltaAIC == 0, "#fc0362", "black")) -> nice_prms
```



```{r}
nice_prms %>% 
  filter(., str_detect(data, "B")) %>% 
  dplyr::select(dist, data, deltaAIC,
                #deltaAICc,
                deltaBIC) %>% 
  distinct() %>% 
  pivot_longer(., cols = starts_with("delta"), names_to = "ic", values_to = "value") %>% 
  filter(value == 0) %>%  
  pivot_wider(., names_from = ic, values_from = dist) %>% 
  mutate(agree = ifelse(deltaAIC == deltaBIC, paste(deltaBIC), paste(deltaBIC, "(BIC),", deltaAIC, "(AIC)"))) %>% 
  dplyr::select(., data, agree) %>% 
  rename(Individual = data,
            `Best model` = agree) -> best_model

knitr::kable(best_model)
# 
# 
# nice_prms %>% 
#   filter(., data != "pop") %>% 
#   dplyr::select(dist, data, deltaAIC,
#                 #deltaAICc,
#                 deltaBIC) %>% 
#   distinct() %>% 
#   pivot_longer(., cols = starts_with("delta"), names_to = "ic", values_to = "value") %>% 
#   filter(value > 0 & value <= 2) %>%  
#   pivot_wider(., names_from = ic, values_from = dist) %>% 
#   mutate(agree = ifelse(deltaAIC == deltaBIC, paste(deltaBIC), paste(deltaBIC, "(BIC),", deltaAIC, "(AIC)"))) %>% 
#   dplyr::select(., data, agree) %>% 
#   rename(Individual = data,
#             `Best model` = agree)

```

However, it is not as straight-forward since there are multiple competing models for certain individuals, which we consider as those within less than 2 units of the delta AIC or BIC. When using AIC, there are competing models for almost every individual, whereas with BIC, only 4 of the individuals have competing models. We should use 4 for BIC and 3 for AIC. Look for the paper Taper Ponciano 2016. 
```{r fig.width=12, fig.height=4}
# To visualize the differences in the information criteria at the individual level

nice_prms %>% 
  filter(., str_detect(data, "B")) %>% 
  dplyr::select(dist, data, deltaAIC, 
                deltaAICc,
                deltaBIC) %>% 
  distinct() %>% 
  pivot_longer(., cols = starts_with("delta"), names_to = "ic", values_to = "value") %>% 
  filter(value >= 0 & value <= 2) %>%  
  mutate(plot_alpha = ifelse(value == "0", 1, 0.8)) %>% 
  ggplot(., aes(x = data, y = value, color = dist 
                #alpha = plot_alpha
                )) +
  facet_wrap(~ic) +
  geom_point(size = 3) +
  scale_color_brewer(palette = "Spectral") + 
  #scale_alpha_continuous(range = c(0.5, 1)) +
  labs(x = "") +
  theme(legend.position = "bottom") +
  guides(color = guide_legend(title = "Distribution"))
  
```
Now we can compare what we call *models*, in which we compare a model that does complete pooling and considers all the data together, and the other model that considers individual variation, and so it fits a separate distribution to the data from each individual.

The individual variation models will fit a distribution to each individual. At one level we will use the same distribution for all individuals and only consider variation in parameters. At the next level, we will consider a change in parameters and distributions, where individuals can have different distributions, and this is what we call the mixed distribution model for individual variation. 


```{r}

# Create the dataframe that compares the models by information criteria
nice_prms %>% 
  filter(., str_detect(data, "B")) %>%
  dplyr::select(., loglik, n, dist, kpars) %>% 
  distinct() %>%
  group_by(dist) %>% 
  summarise(BIC = log(sum(n))*sum(kpars) - 2 * sum(loglik), 
            AIC = 2*(sum(kpars)) - 2*(sum(loglik)),
            AICc = 2*(sum(kpars)) - 2*(sum(loglik)) + (2* sum(kpars) * (sum(kpars)+1)/(sum(n)-sum(kpars)-1))) %>%
    mutate(deltaAIC = signif(AIC - min(AIC), 3),
         deltaAICc = signif(AICc - min(AICc), 3),
         deltaBIC = signif(BIC - min(BIC), 3),
         data = "Individual") %>% 
  full_join(., nice_prms %>%
              filter(., str_detect(data, "B", negate = TRUE)) %>% 
              dplyr::select(dist, BIC, AIC, AICc, deltaAIC, deltaAICc, deltaBIC) %>% 
              distinct() %>% 
              mutate(data = "Population")) -> popind.IC.comp


# Get the multi-distribution model fit
nice_prms %>% 
  filter(., str_detect(data, "B")) %>% 
  dplyr::select(., dist, data, loglik, n, kpars, deltaBIC) %>% 
  dplyr::filter(., deltaBIC == 0) %>% 
  distinct() %>% 
  ungroup() %>% 
  summarise(BIC = log(sum(n))*sum(kpars) - 2 * sum(loglik)) %>% 
  as.numeric() -> multi.BIC

nice_prms %>% 
  filter(., str_detect(data, "B")) %>% 
  dplyr::select(., dist, data, loglik, n, kpars, deltaAIC) %>% 
  dplyr::filter(., deltaAIC == 0) %>% 
  distinct() %>%
  ungroup() %>% 
  summarise(AIC = 2*(sum(kpars)) - 2*(sum(loglik))) %>% 
  as.numeric() -> multi.AIC

nice_prms %>% 
  filter(., str_detect(data, "B")) %>% 
  dplyr::select(., dist, data, loglik, n, kpars, deltaAICc) %>% 
  dplyr::filter(., deltaAICc == 0) %>% 
  distinct() %>%
  ungroup() %>% 
  summarise(AICc = 2*(sum(kpars)) - 2*(sum(loglik)) + (2* sum(kpars) * (sum(kpars)+1)/(sum(n)-sum(kpars)-1))) %>% 
  as.numeric()-> multi.AICc

popind.IC.comp %>% 
  dplyr::select(., dist, BIC, AIC, AICc, data) %>% 
  bind_rows(., data.frame(dist = "Multidist", BIC = multi.BIC, AIC = multi.AIC, AICc = multi.AICc, data = "Multidist")) -> model_comp_IC

```

Considering just focusing on BIC because of JMP's paper, and also in this specific case, it provides less competing models for each individual
```{r}
# Table for BIC and AIC only

model_comp_IC %>% 
  dplyr::select(data, dist, BIC, AIC) %>% 
  group_by(data) %>% 
  mutate(delta_BIC_within = signif(BIC - min(BIC), digits = 2),
         delta_AIC_within = signif(AIC - min(AIC), digits = 2)) %>% 
  ungroup() %>% 
  mutate(delta_BIC_across = signif(BIC - min(BIC), digits = 2),
         delta_AIC_across = signif(AIC - min(AIC), digits = 2)) %>% 
  dplyr::select(., -data) %>% 
  dplyr::select(dist, BIC, delta_BIC_within, delta_BIC_across, AIC, delta_AIC_within, delta_AIC_across)-> data_gt

data_gt$delta_BIC_within[which(data_gt$dist == "Multidist")] <- NA
data_gt$delta_AIC_within[which(data_gt$dist == "Multidist")] <- NA



gt_tbl <- gt(data_gt, rowname_col = "dist")

gt_tbl %>% 
  tab_header(
    title = md("**Model comparisons across levels**")
  ) %>% 
  tab_stubhead(label = "Model") %>% 
  tab_row_group(
    group = "Multidist",
    rows = 9
  ) %>% 
  tab_row_group(
    group = "Individual",
    rows = 1:4
  ) %>% 
  tab_row_group(
    group = "Population", 
    rows = 5:8
  ) %>% 
  tab_spanner(
    label = md("**BIC**"),
    columns = vars(BIC, delta_BIC_within, delta_BIC_across)
  ) %>% 
  tab_spanner(
    label = md("**AIC**"),
    columns = vars(AIC, delta_AIC_within, delta_AIC_across)
  ) %>% 
  cols_label(
    delta_BIC_within = html("&Delta; BIC<sub>within</sub>"),
    delta_BIC_across = html("&Delta; BIC<sub>across</sub>"),
    delta_AIC_within = html("&Delta; AIC<sub>within</sub>"),
    delta_AIC_across = html("&Delta; AIC<sub>across</sub>")
  ) -> gt_table_bic
  
gtsave(gt_table_bic, "aic_bic_table.png")  
```

```{r eval=FALSE}
knitr::include_graphics("aic_bic_table.png")
```

## Probability distribution parameters
We can compare the different parameter values estimated for each distribution and their standard deviations. These parameters can give us some insight into some of the characteristics of each set of distances moved per minute, such as which individuals have higher means or longer tails in the distribution of their distances moved per minute. The x axis in the following plots highlights which individuals have the lowest BIC (yellow) or AIC(magenta) with that model. The blue lines show the value of that parameter for the population level model, and dashed blue lines show the upper and lower limits of that parameter estimate. Overall, at the population level, the lognormal model had the lowest AIC and BIC values.

```{r}

plot_params <- function(prm_data, best_col){
  
  prm_data%>% 
  filter(., data == "POP") %>% 
  dplyr::select(., estimate, sd) -> pop_est
  
  title <- paste(prm_data$dist, prm_data$param)
  
  if(best_col == "BIC"){
    prm_data %>% 
    filter(data != "POP") %>% 
    ggplot(., aes(x = data, y = estimate)) +
    #facet_grid(dist~param, switch = "y", scales = "free") +
    # geom_point() +
    # geom_errorbar(aes(ymin = estimate - sd, ymax = estimate + sd))+
    geom_pointrange(aes(ymin = estimate - sd, ymax = estimate + sd)) +
    geom_hline(aes(yintercept = pop_est$estimate), color = "blue") +
    geom_hline(aes(yintercept = pop_est$estimate + pop_est$sd), color = "blue", linetype = "dashed") +
    geom_hline(aes(yintercept = pop_est$estimate - pop_est$sd), color = "blue", linetype = "dashed") +
    labs(x = "", y = "", subtitle = title) +
    theme(legend.position = "none",
          axis.text.x = element_text(angle = 45, color = prm_data$best_bic)) -> plot
  }
  
  if(best_col == "AIC"){
    prm_data %>% 
    filter(data != "POP") %>% 
    ggplot(., aes(x = data, y = estimate)) +
    #facet_grid(dist~param, switch = "y", scales = "free") +
    # geom_point() +
    # geom_errorbar(aes(ymin = estimate - sd, ymax = estimate + sd))+
    geom_pointrange(aes(ymin = estimate - sd, ymax = estimate + sd)) +
    geom_hline(aes(yintercept = pop_est$estimate), color = "blue") +
    geom_hline(aes(yintercept = pop_est$estimate + pop_est$sd), color = "blue", linetype = "dashed") +
    geom_hline(aes(yintercept = pop_est$estimate - pop_est$sd), color = "blue", linetype = "dashed") +
    labs(x = "", y = "", subtitle = title) +
    theme(legend.position = "none",
          axis.text.x = element_text(angle = 45, color = prm_data$best_aic)) -> plot
  }
  return(plot)
  
          
}

```

```{r fig.height=10, fig.width=12}

nice_prms %>% 
  filter(., dist == "Exponential") %>% 
  plot_params(., best_col = "BIC") +
  #theme(axis.text.x = element_blank()) +
  NULL-> p1

nice_prms %>% 
  filter(., dist == "Gamma" & param == "SHAPE") %>% 
  plot_params(., best_col = "BIC") +
  #theme(axis.text.x = element_blank()) +
  NULL -> p2

nice_prms %>% 
  filter(., dist == "Gamma" & param == "RATE") %>% 
  plot_params(., best_col = "BIC") +
  #theme(axis.text.x = element_blank()) +
  NULL -> p3

nice_prms %>% 
  filter(., dist == "Weibull" & param == "SHAPE") %>% 
  plot_params(., best_col = "BIC") +
  #theme(axis.text.x = element_blank()) +
  NULL-> p4

nice_prms %>% 
  filter(., dist == "Weibull" & param == "SCALE") %>% 
  plot_params(., best_col = "BIC") +
  #theme(axis.text.x = element_blank()) +
  NULL-> p5

nice_prms %>% 
  filter(., dist == "Lognormal" & param == "MEANLOG") %>% 
  plot_params(., best_col = "BIC") -> p6

nice_prms %>% 
  filter(., dist == "Lognormal" & param == "SDLOG") %>% 
  plot_params(., best_col = "BIC") ->p7


plot_grid(p1, NULL, p2, p3, p4, p5, p6, p7, ncol = 2, align = "v") -> bic_grid

nice_prms %>% 
  filter(., dist == "Exponential") %>% 
  plot_params(., best_col = "AIC") +
  #theme(axis.text.x = element_blank()) +
  NULL-> p1

nice_prms %>% 
  filter(., dist == "Gamma" & param == "SHAPE") %>% 
  plot_params(., best_col = "AIC") +
  #theme(axis.text.x = element_blank()) +
  NULL -> p2

nice_prms %>% 
  filter(., dist == "Gamma" & param == "RATE") %>% 
  plot_params(., best_col = "AIC") +
  #theme(axis.text.x = element_blank()) +
  NULL -> p3

nice_prms %>% 
  filter(., dist == "Weibull" & param == "SHAPE") %>% 
  plot_params(., best_col = "AIC") +
  #theme(axis.text.x = element_blank()) +
  NULL-> p4

nice_prms %>% 
  filter(., dist == "Weibull" & param == "SCALE") %>% 
  plot_params(., best_col = "AIC") +
  #theme(axis.text.x = element_blank()) +
  NULL-> p5

nice_prms %>% 
  filter(., dist == "Lognormal" & param == "MEANLOG") %>% 
  plot_params(., best_col = "AIC") -> p6

nice_prms %>% 
  filter(., dist == "Lognormal" & param == "SDLOG") %>% 
  plot_params(., best_col = "AIC") ->p7


plot_grid(p1, NULL, p2, p3, p4, p5, p6, p7, ncol = 2, align = "v") -> aic_grid

plot_grid(bic_grid, aic_grid, ncol = 2)

```


#References






